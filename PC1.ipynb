{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Problem by Software Defect Prediction\n",
    "\n",
    "### Abstract\n",
    "\n",
    "Software defect prediction is a field which has encouraged researchers to develop sophisticated detection techniques using Machine Learning methods. The issues is that often the data available for the problem is highly imbalanced which makes it difficult for the classifiers to detect the defects. In order to overcome this issue several methods have been found out and all these methods can be classified mainly in three different categories namely,\n",
    "\n",
    "#### 1. Resampling based methods:\n",
    "These methods either use undersampling and oversampling techniques in order to transform the imbalanced dataset to a balanced one.\n",
    "\n",
    "#### 2. Cost Sensitive Learning base models:\n",
    "These kind of methods considers the cost associated with misclassifying examples and tries to make the classifier favor to the minority-class by adding different cost factors into the algorithms.\n",
    "\n",
    "#### 3. Ensemble Learning:\n",
    "These kind of methods tries to improve the performance of the imbalanced dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM1 42 344 12.209302325581394\n",
      "JM1 1759 9591 18.340110520279428\n",
      "KC1 325 2095 15.513126491646778\n",
      "KC3 36 200 18.0\n",
      "MC1 68 8737 0.7782991873640838\n",
      "MC2 44 125 35.199999999999996\n",
      "MW1 27 263 10.26615969581749\n",
      "PC1 61 735 8.299319727891156\n",
      "PC2 16 1493 1.0716677829872738\n",
      "PC3 138 1099 12.556869881710647\n",
      "PC4 178 1379 12.907904278462654\n",
      "PC5 502 16962 2.9595566560547106\n"
     ]
    }
   ],
   "source": [
    "#cm1 = pd.read_csv(\"data/CM1.csv\")\n",
    "#print(sum(cm1.Defective == \"Y\"),cm1.shape[0],sum(cm1.Defective == \"Y\")/cm1.shape[0] * 100)\n",
    "#jm1 = pd.read_csv(\"data/JM1.csv\")\n",
    "#print(sum(jm1.label == \"Y\"),jm1.shape[0],sum(jm1.label == \"Y\")/jm1.shape[0] * 100)\n",
    "#kc1 = pd.read_csv(\"data/KC1.csv\")\n",
    "#print(sum(kc1.Defective == \"Y\"),kc1.shape[0],sum(kc1.Defective == \"Y\")/kc1.shape[0] * 100)\n",
    "datasets = ['CM1','JM1','KC1','KC3','KC4','MC1','MC2','MW1','PC1','PC2','PC3','PC4','PC5']\n",
    "d = {}\n",
    "df = pd.DataFrame(columns = [\"Project\",\"Number of Defective instances\",\"Total Number of instances\",\"Percentage of Defective Instances\"]\n",
    ")\n",
    "#df.columns = [\"Project\",\"Number of Defective instances\",\"Total Number of instances\",\"Percentage of Defective Instances\"]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    d[i] = pd.read_csv(\"data/\"+datasets[i]+\".csv\")\n",
    "    try:\n",
    "        df.loc[len(df)] = [datasets[i],sum(d[i][d[i].columns[-1]] == \"Y\"),d[i].shape[0],sum(d[i][d[i].columns[-1]] == \"Y\")/d[i].shape[0] * 100]\n",
    "        print(datasets[i],sum(d[i][d[i].columns[-1]] == \"Y\"),d[i].shape[0],sum(d[i][d[i].columns[-1]] == \"Y\")/d[i].shape[0] * 100)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>Number of Defective instances</th>\n",
       "      <th>Total Number of instances</th>\n",
       "      <th>Percentage of Defective Instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CM1</td>\n",
       "      <td>42</td>\n",
       "      <td>344</td>\n",
       "      <td>12.209302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>JM1</td>\n",
       "      <td>1759</td>\n",
       "      <td>9591</td>\n",
       "      <td>18.340111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KC1</td>\n",
       "      <td>325</td>\n",
       "      <td>2095</td>\n",
       "      <td>15.513126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KC3</td>\n",
       "      <td>36</td>\n",
       "      <td>200</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MC1</td>\n",
       "      <td>68</td>\n",
       "      <td>8737</td>\n",
       "      <td>0.778299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>MC2</td>\n",
       "      <td>44</td>\n",
       "      <td>125</td>\n",
       "      <td>35.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>MW1</td>\n",
       "      <td>27</td>\n",
       "      <td>263</td>\n",
       "      <td>10.266160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PC1</td>\n",
       "      <td>61</td>\n",
       "      <td>735</td>\n",
       "      <td>8.299320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PC2</td>\n",
       "      <td>16</td>\n",
       "      <td>1493</td>\n",
       "      <td>1.071668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>PC3</td>\n",
       "      <td>138</td>\n",
       "      <td>1099</td>\n",
       "      <td>12.556870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PC4</td>\n",
       "      <td>178</td>\n",
       "      <td>1379</td>\n",
       "      <td>12.907904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PC5</td>\n",
       "      <td>502</td>\n",
       "      <td>16962</td>\n",
       "      <td>2.959557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Project Number of Defective instances Total Number of instances  \\\n",
       "0      CM1                            42                       344   \n",
       "1      JM1                          1759                      9591   \n",
       "2      KC1                           325                      2095   \n",
       "3      KC3                            36                       200   \n",
       "4      MC1                            68                      8737   \n",
       "5      MC2                            44                       125   \n",
       "6      MW1                            27                       263   \n",
       "7      PC1                            61                       735   \n",
       "8      PC2                            16                      1493   \n",
       "9      PC3                           138                      1099   \n",
       "10     PC4                           178                      1379   \n",
       "11     PC5                           502                     16962   \n",
       "\n",
       "    Percentage of Defective Instances  \n",
       "0                           12.209302  \n",
       "1                           18.340111  \n",
       "2                           15.513126  \n",
       "3                           18.000000  \n",
       "4                            0.778299  \n",
       "5                           35.200000  \n",
       "6                           10.266160  \n",
       "7                            8.299320  \n",
       "8                            1.071668  \n",
       "9                           12.556870  \n",
       "10                          12.907904  \n",
       "11                           2.959557  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally a dataset whose imbalanced ratio is more than **10:1** can be regarded as **highly imbalanced dataset**. Ordinary classifiers fail under these conditions and thus we require sophisticated techniques. In this analysis we'd try to develop a heuristic about which methods work best in which conditions. We'd work on the following datasets:\n",
    "\n",
    "| Group | Project | Language | Number of Instances | Percentage of Defective Instances |\n",
    "|-------|---------|----------|---------------------|-----------------------------------|\n",
    "| NASA  |   PC5   |    C     |        16962        |              2.95%                |\n",
    "| NASA  |   PC4   |    C     |        1379         |              12.9%                |\n",
    "| NASA  |   JM1   |    C     |        9591         |              18.34%               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd use the following techniques in order to deal with the selected datasets:\n",
    "\n",
    "1. Ordinary Algorithms with Hyper-parameter tuning (if possible):\n",
    "    - Support Vector Machine\n",
    "    - Logistic Regression\n",
    "2. Ensemble Based Methods:\n",
    "    - Random Forests\n",
    "    - Bagging\n",
    "    - Boosting\n",
    "3. Cluster-Based Over-Sampling with Filtering\n",
    "    - Support Vector Machine\n",
    "    - Logistic Regression\n",
    "    - Random Forest\n",
    "    - Bagging\n",
    "    - Boosting\n",
    "\n",
    "Note: we'd use **PCA** in order to reduce the over-fitting if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KC1 = d[2]\n",
    "PC4 = d[11]\n",
    "PC1 = d[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOC_BLANK                            int64\n",
       "BRANCH_COUNT                         int64\n",
       "CALL_PAIRS                           int64\n",
       "LOC_CODE_AND_COMMENT                 int64\n",
       "LOC_COMMENTS                         int64\n",
       "CONDITION_COUNT                      int64\n",
       "CYCLOMATIC_COMPLEXITY                int64\n",
       "CYCLOMATIC_DENSITY                 float64\n",
       "DECISION_COUNT                       int64\n",
       "DECISION_DENSITY                   float64\n",
       "DESIGN_COMPLEXITY                    int64\n",
       "DESIGN_DENSITY                     float64\n",
       "EDGE_COUNT                           int64\n",
       "ESSENTIAL_COMPLEXITY                 int64\n",
       "ESSENTIAL_DENSITY                  float64\n",
       "LOC_EXECUTABLE                       int64\n",
       "PARAMETER_COUNT                      int64\n",
       "HALSTEAD_CONTENT                   float64\n",
       "HALSTEAD_DIFFICULTY                float64\n",
       "HALSTEAD_EFFORT                    float64\n",
       "HALSTEAD_ERROR_EST                 float64\n",
       "HALSTEAD_LENGTH                      int64\n",
       "HALSTEAD_LEVEL                     float64\n",
       "HALSTEAD_PROG_TIME                 float64\n",
       "HALSTEAD_VOLUME                    float64\n",
       "MAINTENANCE_SEVERITY               float64\n",
       "MODIFIED_CONDITION_COUNT             int64\n",
       "MULTIPLE_CONDITION_COUNT             int64\n",
       "NODE_COUNT                           int64\n",
       "NORMALIZED_CYLOMATIC_COMPLEXITY    float64\n",
       "NUM_OPERANDS                         int64\n",
       "NUM_OPERATORS                        int64\n",
       "NUM_UNIQUE_OPERANDS                  int64\n",
       "NUM_UNIQUE_OPERATORS                 int64\n",
       "NUMBER_OF_LINES                      int64\n",
       "PERCENT_COMMENTS                   float64\n",
       "LOC_TOTAL                            int64\n",
       "Defective                           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Analysis for PC1\n",
    "\n",
    "PC1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOC_BLANK                            int64\n",
       "BRANCH_COUNT                         int64\n",
       "CALL_PAIRS                           int64\n",
       "LOC_CODE_AND_COMMENT                 int64\n",
       "LOC_COMMENTS                         int64\n",
       "CONDITION_COUNT                      int64\n",
       "CYCLOMATIC_COMPLEXITY                int64\n",
       "CYCLOMATIC_DENSITY                 float64\n",
       "DECISION_COUNT                       int64\n",
       "DECISION_DENSITY                   float64\n",
       "DESIGN_COMPLEXITY                    int64\n",
       "DESIGN_DENSITY                     float64\n",
       "EDGE_COUNT                           int64\n",
       "ESSENTIAL_COMPLEXITY                 int64\n",
       "ESSENTIAL_DENSITY                  float64\n",
       "LOC_EXECUTABLE                       int64\n",
       "PARAMETER_COUNT                      int64\n",
       "HALSTEAD_CONTENT                   float64\n",
       "HALSTEAD_DIFFICULTY                float64\n",
       "HALSTEAD_EFFORT                    float64\n",
       "HALSTEAD_ERROR_EST                 float64\n",
       "HALSTEAD_LENGTH                      int64\n",
       "HALSTEAD_LEVEL                     float64\n",
       "HALSTEAD_PROG_TIME                 float64\n",
       "HALSTEAD_VOLUME                    float64\n",
       "MAINTENANCE_SEVERITY               float64\n",
       "MODIFIED_CONDITION_COUNT             int64\n",
       "MULTIPLE_CONDITION_COUNT             int64\n",
       "NODE_COUNT                           int64\n",
       "NORMALIZED_CYLOMATIC_COMPLEXITY    float64\n",
       "NUM_OPERANDS                         int64\n",
       "NUM_OPERATORS                        int64\n",
       "NUM_UNIQUE_OPERANDS                  int64\n",
       "NUM_UNIQUE_OPERATORS                 int64\n",
       "NUMBER_OF_LINES                      int64\n",
       "PERCENT_COMMENTS                   float64\n",
       "LOC_TOTAL                            int64\n",
       "Defective                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Correcting Defective label to int\n",
    "\n",
    "PC1['Defective'] = (PC1['Defective'] == \"Y\")*1\n",
    "PC1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK</th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>CALL_PAIRS</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CONDITION_COUNT</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>CYCLOMATIC_DENSITY</th>\n",
       "      <th>DECISION_COUNT</th>\n",
       "      <th>DECISION_DENSITY</th>\n",
       "      <th>...</th>\n",
       "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUM_OPERANDS</th>\n",
       "      <th>NUM_OPERATORS</th>\n",
       "      <th>NUM_UNIQUE_OPERANDS</th>\n",
       "      <th>NUM_UNIQUE_OPERATORS</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>LOC_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "      <td>7.350000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.454575e-16</td>\n",
       "      <td>1.291484e-16</td>\n",
       "      <td>8.398422e-17</td>\n",
       "      <td>-5.078326e-16</td>\n",
       "      <td>4.329870e-16</td>\n",
       "      <td>-3.353327e-17</td>\n",
       "      <td>1.586033e-16</td>\n",
       "      <td>1.603139e-15</td>\n",
       "      <td>2.646409e-16</td>\n",
       "      <td>-3.037026e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.017950e-17</td>\n",
       "      <td>-1.296015e-16</td>\n",
       "      <td>-6.457420e-16</td>\n",
       "      <td>-1.782399e-17</td>\n",
       "      <td>-1.042250e-17</td>\n",
       "      <td>-2.785376e-16</td>\n",
       "      <td>6.797284e-18</td>\n",
       "      <td>3.791374e-17</td>\n",
       "      <td>-1.626420e-15</td>\n",
       "      <td>-1.084544e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-6.124197e-01</td>\n",
       "      <td>-5.629526e-01</td>\n",
       "      <td>-8.935369e-01</td>\n",
       "      <td>-3.310945e-01</td>\n",
       "      <td>-4.776055e-01</td>\n",
       "      <td>-5.498607e-01</td>\n",
       "      <td>-6.450375e-01</td>\n",
       "      <td>-1.969935e+00</td>\n",
       "      <td>-5.307145e-01</td>\n",
       "      <td>-4.355453e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.497144e-01</td>\n",
       "      <td>-5.829778e-01</td>\n",
       "      <td>-1.631291e+00</td>\n",
       "      <td>-6.620310e-01</td>\n",
       "      <td>-6.380924e-01</td>\n",
       "      <td>-7.516631e-01</td>\n",
       "      <td>-1.578774e+00</td>\n",
       "      <td>-6.980089e-01</td>\n",
       "      <td>-8.519218e-01</td>\n",
       "      <td>-6.823274e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-5.431159e-01</td>\n",
       "      <td>-4.484934e-01</td>\n",
       "      <td>-6.147807e-01</td>\n",
       "      <td>-3.310945e-01</td>\n",
       "      <td>-4.776055e-01</td>\n",
       "      <td>-4.151224e-01</td>\n",
       "      <td>-4.372345e-01</td>\n",
       "      <td>-7.191149e-01</td>\n",
       "      <td>-5.307145e-01</td>\n",
       "      <td>-4.355453e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.159263e-01</td>\n",
       "      <td>-4.556125e-01</td>\n",
       "      <td>-7.676455e-01</td>\n",
       "      <td>-4.954752e-01</td>\n",
       "      <td>-4.877675e-01</td>\n",
       "      <td>-5.099205e-01</td>\n",
       "      <td>-6.864537e-01</td>\n",
       "      <td>-5.487981e-01</td>\n",
       "      <td>-8.519218e-01</td>\n",
       "      <td>-4.848920e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-3.352043e-01</td>\n",
       "      <td>-3.340341e-01</td>\n",
       "      <td>-3.360245e-01</td>\n",
       "      <td>-3.310945e-01</td>\n",
       "      <td>-3.959683e-01</td>\n",
       "      <td>-2.803840e-01</td>\n",
       "      <td>-3.333330e-01</td>\n",
       "      <td>-2.500576e-01</td>\n",
       "      <td>-2.466102e-01</td>\n",
       "      <td>-4.355453e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.821382e-01</td>\n",
       "      <td>-2.964059e-01</td>\n",
       "      <td>-3.358229e-01</td>\n",
       "      <td>-3.080999e-01</td>\n",
       "      <td>-2.978834e-01</td>\n",
       "      <td>-2.681780e-01</td>\n",
       "      <td>-1.765563e-01</td>\n",
       "      <td>-3.498503e-01</td>\n",
       "      <td>-3.870507e-01</td>\n",
       "      <td>-2.874566e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.499226e-01</td>\n",
       "      <td>9.343612e-03</td>\n",
       "      <td>2.214879e-01</td>\n",
       "      <td>-8.302676e-02</td>\n",
       "      <td>9.385504e-02</td>\n",
       "      <td>5.646177e-02</td>\n",
       "      <td>8.227303e-02</td>\n",
       "      <td>4.535285e-01</td>\n",
       "      <td>3.749403e-02</td>\n",
       "      <td>9.596026e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.233208e-02</td>\n",
       "      <td>5.384866e-02</td>\n",
       "      <td>6.141869e-01</td>\n",
       "      <td>7.706038e-02</td>\n",
       "      <td>9.770851e-02</td>\n",
       "      <td>2.153071e-01</td>\n",
       "      <td>4.608154e-01</td>\n",
       "      <td>1.806770e-01</td>\n",
       "      <td>6.589093e-01</td>\n",
       "      <td>1.320937e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.498095e+01</td>\n",
       "      <td>1.277155e+01</td>\n",
       "      <td>5.796612e+00</td>\n",
       "      <td>1.157616e+01</td>\n",
       "      <td>1.250271e+01</td>\n",
       "      <td>1.225028e+01</td>\n",
       "      <td>1.338167e+01</td>\n",
       "      <td>3.736930e+00</td>\n",
       "      <td>1.268013e+01</td>\n",
       "      <td>1.285209e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.216016e+01</td>\n",
       "      <td>1.349089e+01</td>\n",
       "      <td>3.464216e+00</td>\n",
       "      <td>1.121548e+01</td>\n",
       "      <td>1.229776e+01</td>\n",
       "      <td>1.544509e+01</td>\n",
       "      <td>1.053129e+01</td>\n",
       "      <td>1.360965e+01</td>\n",
       "      <td>3.376843e+00</td>\n",
       "      <td>1.410065e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LOC_BLANK  BRANCH_COUNT    CALL_PAIRS  LOC_CODE_AND_COMMENT  \\\n",
       "count  7.350000e+02  7.350000e+02  7.350000e+02          7.350000e+02   \n",
       "mean   2.454575e-16  1.291484e-16  8.398422e-17         -5.078326e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00          1.000000e+00   \n",
       "min   -6.124197e-01 -5.629526e-01 -8.935369e-01         -3.310945e-01   \n",
       "25%   -5.431159e-01 -4.484934e-01 -6.147807e-01         -3.310945e-01   \n",
       "50%   -3.352043e-01 -3.340341e-01 -3.360245e-01         -3.310945e-01   \n",
       "75%    1.499226e-01  9.343612e-03  2.214879e-01         -8.302676e-02   \n",
       "max    1.498095e+01  1.277155e+01  5.796612e+00          1.157616e+01   \n",
       "\n",
       "       LOC_COMMENTS  CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  \\\n",
       "count  7.350000e+02     7.350000e+02           7.350000e+02   \n",
       "mean   4.329870e-16    -3.353327e-17           1.586033e-16   \n",
       "std    1.000000e+00     1.000000e+00           1.000000e+00   \n",
       "min   -4.776055e-01    -5.498607e-01          -6.450375e-01   \n",
       "25%   -4.776055e-01    -4.151224e-01          -4.372345e-01   \n",
       "50%   -3.959683e-01    -2.803840e-01          -3.333330e-01   \n",
       "75%    9.385504e-02     5.646177e-02           8.227303e-02   \n",
       "max    1.250271e+01     1.225028e+01           1.338167e+01   \n",
       "\n",
       "       CYCLOMATIC_DENSITY  DECISION_COUNT  DECISION_DENSITY  ...  \\\n",
       "count        7.350000e+02    7.350000e+02      7.350000e+02  ...   \n",
       "mean         1.603139e-15    2.646409e-16     -3.037026e-15  ...   \n",
       "std          1.000000e+00    1.000000e+00      1.000000e+00  ...   \n",
       "min         -1.969935e+00   -5.307145e-01     -4.355453e-01  ...   \n",
       "25%         -7.191149e-01   -5.307145e-01     -4.355453e-01  ...   \n",
       "50%         -2.500576e-01   -2.466102e-01     -4.355453e-01  ...   \n",
       "75%          4.535285e-01    3.749403e-02      9.596026e-02  ...   \n",
       "max          3.736930e+00    1.268013e+01      1.285209e+01  ...   \n",
       "\n",
       "       MULTIPLE_CONDITION_COUNT    NODE_COUNT  \\\n",
       "count              7.350000e+02  7.350000e+02   \n",
       "mean              -4.017950e-17 -1.296015e-16   \n",
       "std                1.000000e+00  1.000000e+00   \n",
       "min               -5.497144e-01 -5.829778e-01   \n",
       "25%               -4.159263e-01 -4.556125e-01   \n",
       "50%               -2.821382e-01 -2.964059e-01   \n",
       "75%                5.233208e-02  5.384866e-02   \n",
       "max                1.216016e+01  1.349089e+01   \n",
       "\n",
       "       NORMALIZED_CYLOMATIC_COMPLEXITY  NUM_OPERANDS  NUM_OPERATORS  \\\n",
       "count                     7.350000e+02  7.350000e+02   7.350000e+02   \n",
       "mean                     -6.457420e-16 -1.782399e-17  -1.042250e-17   \n",
       "std                       1.000000e+00  1.000000e+00   1.000000e+00   \n",
       "min                      -1.631291e+00 -6.620310e-01  -6.380924e-01   \n",
       "25%                      -7.676455e-01 -4.954752e-01  -4.877675e-01   \n",
       "50%                      -3.358229e-01 -3.080999e-01  -2.978834e-01   \n",
       "75%                       6.141869e-01  7.706038e-02   9.770851e-02   \n",
       "max                       3.464216e+00  1.121548e+01   1.229776e+01   \n",
       "\n",
       "       NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  NUMBER_OF_LINES  \\\n",
       "count         7.350000e+02          7.350000e+02     7.350000e+02   \n",
       "mean         -2.785376e-16          6.797284e-18     3.791374e-17   \n",
       "std           1.000000e+00          1.000000e+00     1.000000e+00   \n",
       "min          -7.516631e-01         -1.578774e+00    -6.980089e-01   \n",
       "25%          -5.099205e-01         -6.864537e-01    -5.487981e-01   \n",
       "50%          -2.681780e-01         -1.765563e-01    -3.498503e-01   \n",
       "75%           2.153071e-01          4.608154e-01     1.806770e-01   \n",
       "max           1.544509e+01          1.053129e+01     1.360965e+01   \n",
       "\n",
       "       PERCENT_COMMENTS     LOC_TOTAL  \n",
       "count      7.350000e+02  7.350000e+02  \n",
       "mean      -1.626420e-15 -1.084544e-16  \n",
       "std        1.000000e+00  1.000000e+00  \n",
       "min       -8.519218e-01 -6.823274e-01  \n",
       "25%       -8.519218e-01 -4.848920e-01  \n",
       "50%       -3.870507e-01 -2.874566e-01  \n",
       "75%        6.589093e-01  1.320937e-01  \n",
       "max        3.376843e+00  1.410065e+01  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Since, the number of defective instances is very less, we'd use 10-Fold cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score,balanced_accuracy_score\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "X = PC1[PC1.columns[:-1]]\n",
    "y = PC1[PC1.columns[-1]]\n",
    "yo = y.copy()\n",
    "\n",
    "X = (X-X.mean())/X.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(PC1['Defective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.57075357, 10.07727277,  6.1846134 ,  4.51684265,  4.1101382 ,\n",
       "        3.21640136,  2.70358739,  2.07406149])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'd use PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "XT = pca.fit_transform(X)\n",
    "pca.explained_variance_ratio_*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-2.521388</td>\n",
       "      <td>0.822144</td>\n",
       "      <td>1.708837</td>\n",
       "      <td>0.134342</td>\n",
       "      <td>-0.037248</td>\n",
       "      <td>-0.616636</td>\n",
       "      <td>-0.110241</td>\n",
       "      <td>0.972536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-3.137713</td>\n",
       "      <td>0.592765</td>\n",
       "      <td>1.712132</td>\n",
       "      <td>-1.220505</td>\n",
       "      <td>0.550420</td>\n",
       "      <td>1.360461</td>\n",
       "      <td>0.101228</td>\n",
       "      <td>0.349711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.982195</td>\n",
       "      <td>-2.613912</td>\n",
       "      <td>-2.798527</td>\n",
       "      <td>1.742143</td>\n",
       "      <td>-1.129623</td>\n",
       "      <td>0.240516</td>\n",
       "      <td>0.199956</td>\n",
       "      <td>0.753890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.358768</td>\n",
       "      <td>-1.901431</td>\n",
       "      <td>-0.383355</td>\n",
       "      <td>-0.207482</td>\n",
       "      <td>-0.372655</td>\n",
       "      <td>1.554141</td>\n",
       "      <td>1.134323</td>\n",
       "      <td>-0.197235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.600955</td>\n",
       "      <td>-4.332267</td>\n",
       "      <td>-0.980958</td>\n",
       "      <td>3.393093</td>\n",
       "      <td>2.598393</td>\n",
       "      <td>0.395955</td>\n",
       "      <td>-0.022758</td>\n",
       "      <td>-0.793893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0 -2.521388  0.822144  1.708837  0.134342 -0.037248 -0.616636 -0.110241   \n",
       "1 -3.137713  0.592765  1.712132 -1.220505  0.550420  1.360461  0.101228   \n",
       "2  3.982195 -2.613912 -2.798527  1.742143 -1.129623  0.240516  0.199956   \n",
       "3 -2.358768 -1.901431 -0.383355 -0.207482 -0.372655  1.554141  1.134323   \n",
       "4  8.600955 -4.332267 -0.980958  3.393093  2.598393  0.395955 -0.022758   \n",
       "\n",
       "        pc8  \n",
       "0  0.972536  \n",
       "1  0.349711  \n",
       "2  0.753890  \n",
       "3 -0.197235  \n",
       "4 -0.793893  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(pca.explained_variance_ratio_.shape[0]):\n",
    "    df[\"pc%i\" % (i+1)] = XT[:,i]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.15384615384615385\n",
      "Batch Balanced Accuracy: 0.41396011396011395\n",
      "Recall: 0.25\n",
      "Batch Balanced Accuracy: 0.5657407407407408\n",
      "Recall: 0.3333333333333333\n",
      "Batch Balanced Accuracy: 0.5592592592592592\n",
      "Recall: 0.16666666666666666\n",
      "Batch Balanced Accuracy: 0.4907407407407407\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.5043532338308457\n",
      "===============\n",
      "Average Balanced Accuracy: 0.5068108177063402\n",
      "Std Balanced Accuracy: 0.054971110828370924\n",
      "Average Recall Score: 0.19743589743589746\n",
      "Std Recall Score: 0.08613629247302987\n"
     ]
    }
   ],
   "source": [
    "#params_grid = {'C':[100,1000,10000],'gamma':[0.1,0.01,0.001],'kernel':['rbf']}\n",
    "\n",
    "bal = []\n",
    "recall = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train,test in kf.split(df,y):\n",
    "    Xtrain,Xtest = df.values[train],df.values[test]\n",
    "    ytrain,ytest = y.values[train],y.values[test]\n",
    "    svm = SVC(kernel = \"rbf\",gamma = \"auto\",class_weight=\"balanced\")\n",
    "    #grid = GridSearchCV(svm,params_grid,refit = True,verbose = 0,scoring = 'balanced_accuracy',cv = 5)\n",
    "    svm.fit(Xtrain,ytrain)\n",
    "    #print(grid.best_estimator_)\n",
    "    grid_predictions = svm.predict(Xtest)\n",
    "    r = recall_score(ytest,grid_predictions)\n",
    "    b = balanced_accuracy_score(ytest,grid_predictions)\n",
    "    print(\"Recall:\",r)\n",
    "    print(\"Batch Balanced Accuracy:\",b)\n",
    "    bal += [b]\n",
    "    recall += [r]\n",
    "\n",
    "bal = np.array(bal)\n",
    "recall = np.array(recall)\n",
    "print(\"===============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.07692307692307693\n",
      "Batch Balanced Accuracy: 0.5236467236467236\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.537962962962963\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.537962962962963\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.5416666666666666\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.5416666666666666\n",
      "============\n",
      "Average Balanced Accuracy: 0.5365811965811965\n",
      "Std Balanced Accuracy: 0.006675974217155054\n",
      "Average Recall Score: 0.08205128205128204\n",
      "Std Recall Score: 0.0025641025641025606\n"
     ]
    }
   ],
   "source": [
    "bal = []\n",
    "recall = []\n",
    "\n",
    "#param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "for train,test in kf.split(df,y):\n",
    "    Xtrain,Xtest = df.values[train],df.values[test]\n",
    "    ytrain,ytest = y.values[train],y.values[test]\n",
    "    lr = LogisticRegression(solver = 'lbfgs')\n",
    "    #grid = GridSearchCV(lr,param_grid,refit = True,verbose = 0,scoring = 'balanced_accuracy',cv = 5)\n",
    "    lr.fit(Xtrain,ytrain)\n",
    "    #print(grid.best_estimator_)\n",
    "    y_pred = lr.predict(Xtest)\n",
    "    r = recall_score(ytest,y_pred)\n",
    "    b = balanced_accuracy_score(ytest,y_pred)\n",
    "    print(\"Recall:\",r)\n",
    "    print(\"Batch Balanced Accuracy:\",b)\n",
    "    bal += [b]\n",
    "    recall += [r]\n",
    "\n",
    "print(\"============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd try ensemble based models such as:\n",
    "- Random Forest\n",
    "- Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.15384615384615385\n",
      "Batch Balanced Accuracy: 0.550997150997151\n",
      "Recall: 0.16666666666666666\n",
      "Batch Balanced Accuracy: 0.5796296296296296\n",
      "Recall: 0.0\n",
      "Batch Balanced Accuracy: 0.5\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.537962962962963\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.5416666666666666\n",
      "===========\n",
      "Average Balanced Accuracy: 0.542051282051282\n",
      "Std Balanced Accuracy: 0.025602083438791598\n",
      "Average Recall Score: 0.09743589743589742\n",
      "Std Recall Score: 0.059777144753203934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "bal = []\n",
    "recall = []\n",
    "\n",
    "for train,test in kf.split(df,y):\n",
    "    Xtrain,Xtest = df.values[train],df.values[test]\n",
    "    ytrain,ytest = y.values[train],y.values[test]\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    #grid = GridSearchCV(lr,param_grid,refit = True,verbose = 0,scoring = 'balanced_accuracy',cv = 5)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    #print(grid.best_estimator_)\n",
    "    y_pred = rf.predict(Xtest)\n",
    "    r = recall_score(ytest,y_pred)\n",
    "    b = balanced_accuracy_score(ytest,y_pred)\n",
    "    print(\"Recall:\",r)\n",
    "    print(\"Batch Balanced Accuracy:\",b)\n",
    "    bal += [b]\n",
    "    recall += [r]\n",
    "\n",
    "bal = np.array(bal)\n",
    "recall = np.array(recall)\n",
    "print(\"===========\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.38461538461538464\n",
      "Batch Balanced Accuracy: 0.6737891737891738\n",
      "Recall: 0.16666666666666666\n",
      "Batch Balanced Accuracy: 0.575925925925926\n",
      "Recall: 0.25\n",
      "Batch Balanced Accuracy: 0.6101851851851852\n",
      "Recall: 0.08333333333333333\n",
      "Batch Balanced Accuracy: 0.5231481481481481\n",
      "Recall: 0.16666666666666666\n",
      "Batch Balanced Accuracy: 0.568407960199005\n",
      "===========\n",
      "Average Balanced Accuracy: 0.5902912786494876\n",
      "Std Balanced Accuracy: 0.050122068929377955\n",
      "Average Recall Score: 0.21025641025641026\n",
      "Std Recall Score: 0.1018726693606099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "bal = []\n",
    "recall = []\n",
    "\n",
    "for train,test in kf.split(df,y):\n",
    "    Xtrain,Xtest = df.values[train],df.values[test]\n",
    "    ytrain,ytest = y.values[train],y.values[test]\n",
    "    nb = GaussianNB()\n",
    "    #grid = GridSearchCV(lr,param_grid,refit = True,verbose = 0,scoring = 'balanced_accuracy',cv = 5)\n",
    "    nb.fit(Xtrain,ytrain)\n",
    "    #print(grid.best_estimator_)\n",
    "    y_pred = nb.predict(Xtest)\n",
    "    r = recall_score(ytest,y_pred)\n",
    "    b = balanced_accuracy_score(ytest,y_pred)\n",
    "    print(\"Recall:\",r)\n",
    "    print(\"Batch Balanced Accuracy:\",b)\n",
    "    bal += [b]\n",
    "    recall += [r]\n",
    "\n",
    "bal = np.array(bal)\n",
    "recall = np.array(recall)\n",
    "print(\"===========\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-2.521388</td>\n",
       "      <td>0.822144</td>\n",
       "      <td>1.708837</td>\n",
       "      <td>0.134342</td>\n",
       "      <td>-0.037248</td>\n",
       "      <td>-0.616636</td>\n",
       "      <td>-0.110241</td>\n",
       "      <td>0.972536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-3.137713</td>\n",
       "      <td>0.592765</td>\n",
       "      <td>1.712132</td>\n",
       "      <td>-1.220505</td>\n",
       "      <td>0.550420</td>\n",
       "      <td>1.360461</td>\n",
       "      <td>0.101228</td>\n",
       "      <td>0.349711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.982195</td>\n",
       "      <td>-2.613912</td>\n",
       "      <td>-2.798527</td>\n",
       "      <td>1.742143</td>\n",
       "      <td>-1.129623</td>\n",
       "      <td>0.240516</td>\n",
       "      <td>0.199956</td>\n",
       "      <td>0.753890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.358768</td>\n",
       "      <td>-1.901431</td>\n",
       "      <td>-0.383355</td>\n",
       "      <td>-0.207482</td>\n",
       "      <td>-0.372655</td>\n",
       "      <td>1.554141</td>\n",
       "      <td>1.134323</td>\n",
       "      <td>-0.197235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.600955</td>\n",
       "      <td>-4.332267</td>\n",
       "      <td>-0.980958</td>\n",
       "      <td>3.393093</td>\n",
       "      <td>2.598393</td>\n",
       "      <td>0.395955</td>\n",
       "      <td>-0.022758</td>\n",
       "      <td>-0.793893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>16.753565</td>\n",
       "      <td>-1.873700</td>\n",
       "      <td>1.117572</td>\n",
       "      <td>1.402874</td>\n",
       "      <td>-4.386335</td>\n",
       "      <td>4.051415</td>\n",
       "      <td>-1.815742</td>\n",
       "      <td>3.185775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>731</td>\n",
       "      <td>-1.076460</td>\n",
       "      <td>-1.780674</td>\n",
       "      <td>0.148264</td>\n",
       "      <td>0.493565</td>\n",
       "      <td>-0.837638</td>\n",
       "      <td>0.239646</td>\n",
       "      <td>-0.121430</td>\n",
       "      <td>-0.659616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>732</td>\n",
       "      <td>1.544871</td>\n",
       "      <td>-0.540507</td>\n",
       "      <td>1.109615</td>\n",
       "      <td>0.381071</td>\n",
       "      <td>-1.213654</td>\n",
       "      <td>-0.612453</td>\n",
       "      <td>-1.611542</td>\n",
       "      <td>-0.651792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>733</td>\n",
       "      <td>-0.676700</td>\n",
       "      <td>0.647131</td>\n",
       "      <td>-0.698357</td>\n",
       "      <td>0.126723</td>\n",
       "      <td>0.575452</td>\n",
       "      <td>-0.997832</td>\n",
       "      <td>-0.006964</td>\n",
       "      <td>0.421220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>734</td>\n",
       "      <td>-2.993662</td>\n",
       "      <td>-0.493991</td>\n",
       "      <td>1.172111</td>\n",
       "      <td>-1.099805</td>\n",
       "      <td>0.721696</td>\n",
       "      <td>1.291824</td>\n",
       "      <td>0.400290</td>\n",
       "      <td>0.143016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    -2.521388  0.822144  1.708837  0.134342 -0.037248 -0.616636 -0.110241   \n",
       "1    -3.137713  0.592765  1.712132 -1.220505  0.550420  1.360461  0.101228   \n",
       "2     3.982195 -2.613912 -2.798527  1.742143 -1.129623  0.240516  0.199956   \n",
       "3    -2.358768 -1.901431 -0.383355 -0.207482 -0.372655  1.554141  1.134323   \n",
       "4     8.600955 -4.332267 -0.980958  3.393093  2.598393  0.395955 -0.022758   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "730  16.753565 -1.873700  1.117572  1.402874 -4.386335  4.051415 -1.815742   \n",
       "731  -1.076460 -1.780674  0.148264  0.493565 -0.837638  0.239646 -0.121430   \n",
       "732   1.544871 -0.540507  1.109615  0.381071 -1.213654 -0.612453 -1.611542   \n",
       "733  -0.676700  0.647131 -0.698357  0.126723  0.575452 -0.997832 -0.006964   \n",
       "734  -2.993662 -0.493991  1.172111 -1.099805  0.721696  1.291824  0.400290   \n",
       "\n",
       "          pc8  \n",
       "0    0.972536  \n",
       "1    0.349711  \n",
       "2    0.753890  \n",
       "3   -0.197235  \n",
       "4   -0.793893  \n",
       "..        ...  \n",
       "730  3.185775  \n",
       "731 -0.659616  \n",
       "732 -0.651792  \n",
       "733  0.421220  \n",
       "734  0.143016  \n",
       "\n",
       "[735 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os_elm import OS_ELM\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a, axis=-1).reshape(-1, 1)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a, axis=-1).reshape(-1, 1)\n",
    "    return exp_a / sum_exp_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/parm_khakhar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Recall: 0.9230769230769231\n",
      "Batch Balanced Accuracy: 0.6170940170940171\n",
      "Recall: 0.4166666666666667\n",
      "Batch Balanced Accuracy: 0.27870370370370373\n",
      "Recall: 0.75\n",
      "Batch Balanced Accuracy: 0.6675925925925925\n",
      "Recall: 0.75\n",
      "Batch Balanced Accuracy: 0.6305555555555555\n",
      "Recall: 0.5833333333333334\n",
      "Batch Balanced Accuracy: 0.6349502487562189\n",
      "================\n",
      "Average Balanced Accuracy: 0.5657792235404175\n",
      "Std Balanced Accuracy: 0.14449368717245942\n",
      "Average Recall Score: 0.6846153846153846\n",
      "Std Recall Score: 0.17173745691938824\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_input_nodes = 8\n",
    "n_hidden_nodes = 4\n",
    "n_output_nodes = 1\n",
    "bal = []\n",
    "recall = []\n",
    "\n",
    "for train,test in kf.split(df,y):\n",
    "    Xtrain,Xtest = df.values[train],df.values[test]\n",
    "    ytrain,ytest = y.values[train],y.values[test]\n",
    "    ytrain = ytrain.reshape(-1,1)\n",
    "    ytest = ytest.reshape(-1,1)\n",
    "    os_elm1 = OS_ELM(\n",
    "        # the number of input nodes.\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        # the number of hidden nodes.\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        # the number of output nodes.\n",
    "        n_output_nodes=n_output_nodes,\n",
    "        # loss function.\n",
    "        # the default value is 'mean_squared_error'.\n",
    "        # for the other functions, we support\n",
    "        # 'mean_absolute_error', 'categorical_crossentropy', and 'binary_crossentropy'.\n",
    "        loss='binary_crossentropy',\n",
    "        # activation function applied to the hidden nodes.\n",
    "        # the default value is 'sigmoid'.\n",
    "        # for the other functions, we support 'linear' and 'tanh'.\n",
    "        # NOTE: OS-ELM can apply an activation function only to the hidden nodes.\n",
    "        activation='tanh',\n",
    "    )\n",
    "    border = int(2*n_hidden_nodes)\n",
    "    Xtrain_init = Xtrain[:border]\n",
    "    Xtrain_seq = Xtrain[border:]\n",
    "    ytrain_init = ytrain[:border]\n",
    "    ytrain_seq = ytrain[border:]\n",
    "    os_elm1.init_train(Xtrain_init, ytrain_init)\n",
    "    batch_size = 64\n",
    "    for i in range(0, len(Xtrain_seq), batch_size):\n",
    "        x_batch = Xtrain_seq[i:i+batch_size]\n",
    "        t_batch = ytrain_seq[i:i+batch_size]\n",
    "        os_elm1.seq_train(x_batch, t_batch)\n",
    "    n_classes = n_output_nodes\n",
    "    y_pred = os_elm1.predict(Xtest)\n",
    "    y_pred = (1/(1+np.exp(-1*y_pred))>0.5)*1\n",
    "    r = recall_score(ytest,y_pred)\n",
    "    b = balanced_accuracy_score(ytest,y_pred)\n",
    "    print(\"Recall:\",r)\n",
    "    print(\"Batch Balanced Accuracy:\",b)\n",
    "    bal += [b]\n",
    "    recall += [r]\n",
    "    tf.reset_default_graph()\n",
    "print(\"================\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest also produces results similar to Logistic Regression and SVMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average recall score as well as balanced accuracy score are higher for **Random Forest** as compared to the **SVM** and **Logistic Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd use the **KMFOS** technique which would generate extra samples and balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for KMFOS\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Noise filtering step\n",
    "\n",
    "def clni(n):\n",
    "    nbrs = NearestNeighbors(n_neighbors = n, algorithm = 'auto', p = 2).fit(compData)\n",
    "    distances,indices = nbrs.kneighbors(compData)\n",
    "    dropped = []\n",
    "    i = 0\n",
    "    while i <len(compData):\n",
    "        t,f = 0,0\n",
    "        for j in range(n-1):\n",
    "            if compData['defects'][indices[i][j+1]] == True:\n",
    "                t += 1\n",
    "            else:\n",
    "                f += 1\n",
    "        if t>f and compData['defects'][i] == False:\n",
    "            dropped.append(i)\n",
    "        elif f>t and compData['defects'][i] == True:\n",
    "            dropped.append(i)\n",
    "        i+=1\n",
    "    return dropped\n",
    "\n",
    "# Over-sampling step\n",
    "\n",
    "def overSamplingM(clusters,d,nplus,n):\n",
    "    k = len(clusters)\n",
    "    t = 0\n",
    "    s = 0\n",
    "    first = False\n",
    "    second = False\n",
    "    for i in range(k):\n",
    "        first = False\n",
    "        second = False\n",
    "        ni = len(clusters[i])\n",
    "        for j in range(i+1,k):\n",
    "            nj = len(clusters[j])\n",
    "            if ni + nj == 0:\n",
    "                continue\n",
    "            alpha = ni/(ni+nj)\n",
    "            beta = nj/(ni+nj)\n",
    "            total = ((ni+nj)/((k-1)*nplus))*n\n",
    "            t += total\n",
    "            r = int(total)\n",
    "            if(total-r > 0.5):\n",
    "                r = r+1\n",
    "            s += r\n",
    "            for l in range(r):\n",
    "                if ni:\n",
    "                    p = clusters[i].sample()\n",
    "                    #print(\"P:\",p)\n",
    "                    first = True\n",
    "                if nj:\n",
    "                    q = clusters[j].sample()\n",
    "                    #print(\"Q:\",q)\n",
    "                    second = True\n",
    "                if first and second:\n",
    "                    m = alpha*p[p.columns[:-1]] + beta*q[q.columns[:-1]].values\n",
    "                    m['defects'] = True\n",
    "                    #print(\"M:\",m)\n",
    "                    d = d.append(m,ignore_index = True)\n",
    "                elif first:\n",
    "                    m = alpha*p[:-1]\n",
    "                    m['defects'] = True\n",
    "                    #print(m)\n",
    "                    d = d.append(m,ignore_index = True)\n",
    "                elif second:\n",
    "                    m = beta*q[:-1]\n",
    "                    m['defects'] = True\n",
    "                    #print(m)\n",
    "                    d = d.append(m,ignore_index = True)  \n",
    "    #print(s)\n",
    "    #print(t)\n",
    "    return d\n",
    "\n",
    "def overSampling(clusters,d,nplus,n):\n",
    "    k = len(clusters)\n",
    "    t = 0\n",
    "    s = 0\n",
    "    first = False\n",
    "    second = False\n",
    "    for i in range(k):\n",
    "        if len(clusters[i].groupby('defects').groups) == 1:\n",
    "            first = False\n",
    "            if clusters[i].defects.values[0]:\n",
    "                first = True\n",
    "                ni = len(clusters[i])\n",
    "            else:\n",
    "                ni = 0\n",
    "        else:\n",
    "            first = True\n",
    "            ni = len(clusters[i].groupby('defects').groups[True])\n",
    "        for j in range(i+1,k):\n",
    "            if len(clusters[j].groupby('defects').groups) == 1:\n",
    "                second = False\n",
    "                if clusters[j].defects.values[0]:\n",
    "                    second = True\n",
    "                    nj = len(clusters[j])\n",
    "                else:\n",
    "                    nj = 0\n",
    "            else:\n",
    "                second = True\n",
    "                nj = len(clusters[j].groupby('defects').groups[True])\n",
    "            if ni+nj == 0:\n",
    "                continue\n",
    "            alpha = ni/(ni+nj)\n",
    "            beta = nj/(ni+nj)\n",
    "            total = ((ni+nj)/((k-1)*nplus))*n\n",
    "            r = int(total)\n",
    "            if(total-r > 0.5):\n",
    "                r = r+1\n",
    "            for m in range(r):\n",
    "                # Remove last column\n",
    "                if first:\n",
    "                    p = d.iloc[random.choice(clusters[i].groupby('defects').groups[True])]\n",
    "                if second:\n",
    "                    q = d.iloc[random.choice(clusters[j].groupby('defects').groups[True])]\n",
    "                if first and second:\n",
    "                    m = alpha*p[:-1] + beta*q[:-1]\n",
    "                    m['defects'] = True\n",
    "                    d = d.append(m,ignore_index = True)\n",
    "                elif first:\n",
    "                    m = alpha*p[:-1]\n",
    "                    m['defects'] = True\n",
    "                    d = d.append(m,ignore_index = True)\n",
    "                elif second:\n",
    "                    m = beta*q[:-1]\n",
    "                    m['defects'] = True\n",
    "                    d = d.append(m,ignore_index = True)\n",
    "    return d\n",
    "\n",
    "# Code for peforming initial clustering\n",
    "\n",
    "def InitialClustering(dat,k):\n",
    "    kmeans = KMeans(n_clusters = k, init = 'k-means++',max_iter=300,n_init = 10,random_state = 0)\n",
    "    kmeans.fit(dat)\n",
    "    clusters = {}\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        if kmeans.labels_[i] in clusters:\n",
    "            clusters[kmeans.labels_[i]].append(dat.index[i])\n",
    "        else:\n",
    "            clusters[kmeans.labels_[i]] = [dat.index[i]]\n",
    "    for key in clusters.keys():\n",
    "        clusters[key] = np.array(clusters[key])\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "data = df\n",
    "data['defects'] = (y == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf10 = StratifiedKFold(n_splits=10)\n",
    "\n",
    "folds = []\n",
    "for train,test in kf10.split(df[df.columns[:-1]],df[df.columns[-1]]):\n",
    "    Xtrain = df.loc[train]\n",
    "    Xtest,ytest = df.values[:,:-1][test],df.values[:,-1][test]\n",
    "    test = (Xtest,ytest)\n",
    "    params = {3:[5,15,20],5:[5,15,20],20:[5,15,20],50:[5,15,20]}\n",
    "    result = {}\n",
    "    key = 3\n",
    "    val = 5\n",
    "    for key in params.keys():\n",
    "        for val in params[key]:\n",
    "            X = Xtrain.copy()\n",
    "            temp = Xtrain.defects\n",
    "            X.index = [i for i in range(len(X))]\n",
    "            Np = sum(X['defects'] == True)\n",
    "            Nm = sum(X['defects'] == False)\n",
    "            N = Nm - Np\n",
    "            D = X.loc[X['defects'] == True]\n",
    "            clusters = InitialClustering(D,key)\n",
    "            for i in clusters.keys():\n",
    "                clusters[i] = X.loc[clusters[i]]\n",
    "            compData = overSamplingM(clusters,X,Np,N)\n",
    "            compData = compData.dropna()\n",
    "            #print(\"DefectiveInstances:\",len(compData.groupby(\"defects\").groups[True]))\n",
    "            #print(\"NonDefectiveInstances:\",len(compData.groupby(\"defects\").groups[False]))\n",
    "            dropped = clni(val)\n",
    "            result[(key,val)] = compData.drop(index = dropped)\n",
    "            #print(\"Defect:\",len(result[(key,val)].groupby('defects').groups[True]))\n",
    "            #print(\"NonDefect:\",len(result[(key,val)].groupby('defects').groups[False]))\n",
    "    print(\"Complete\")    \n",
    "    folds.append((result,test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of KMFOS method are **k** and **kn** which are the initial number of clusters formed and also the number of neighbors used for noise filtering step. For more details refer the paper. Now we'd simply fit the model on the balanced data set for each of the values of the parameters and average out the results. We'd use **80-20** split for each of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.6363424038769736\n",
      "Std Balanced Accuracy: 0.11874368687356067\n",
      "Average Recall Score: 0.5146825396825396\n",
      "Std Recall Score: 0.29563119205063243\n"
     ]
    }
   ],
   "source": [
    "bal = []\n",
    "recall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    #bal = []\n",
    "    #recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects']\n",
    "        lr = LogisticRegression(solver = \"lbfgs\")\n",
    "        lr.fit(X,Y)\n",
    "        y_pred = lr.predict(fold[1][0])\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,y_pred)\n",
    "        r = recall_score(l,y_pred)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "        \n",
    "bal = np.array(bal)\n",
    "recall = np.array(recall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.583952131847764\n",
      "Std Balanced Accuracy: 0.11122502454999865\n",
      "Average Recall Score: 0.3198412698412698\n",
      "Std Recall Score: 0.25823060157116445\n"
     ]
    }
   ],
   "source": [
    "bal = []\n",
    "recall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    #bal = []\n",
    "    #recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects']\n",
    "        svm = SVC(gamma = 'auto',kernel = 'rbf')\n",
    "        svm.fit(X,Y)\n",
    "        y_pred = svm.predict(fold[1][0])\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,y_pred)\n",
    "        r = recall_score(l,y_pred)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "    #bal = np.array(bal)\n",
    "    #recall = np.array(recall)\n",
    "    #print(\"Recall:\",np.mean(recall))\n",
    "    #print(\"Balanced Accuracy:\",np.mean(bal))\n",
    "    #print(\"====================\")\n",
    "    #mbal += [np.mean(bal)]\n",
    "    #mrecall += [np.mean(recall)]\n",
    "\n",
    "bal = np.array(bal)\n",
    "recall = np.array(recall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.6032635753306297\n",
      "Std Balanced Accuracy: 0.11443241336719867\n",
      "Average Recall Score: 0.3664682539682539\n",
      "Std Recall Score: 0.2536821770471334\n"
     ]
    }
   ],
   "source": [
    "bal = []\n",
    "recall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    #bal = []\n",
    "    #recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects']\n",
    "        rf = RandomForestClassifier(n_estimators=100)\n",
    "        rf.fit(X,Y)\n",
    "        y_pred = rf.predict(fold[1][0])\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,y_pred)\n",
    "        r = recall_score(l,y_pred)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "    #bal = np.array(bal)\n",
    "    #recall = np.array(recall)\n",
    "    #print(\"Recall:\",np.mean(recall))\n",
    "    #print(\"Balanced Accuracy:\",np.mean(bal))\n",
    "    #print(\"====================\")\n",
    "    #mbal += [np.mean(bal)]\n",
    "    #mrecall += [np.mean(recall)]\n",
    "\n",
    "bal = np.array(bal)\n",
    "recall = np.array(recall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.6134594447231628\n",
      "Std Balanced Accuracy: 0.11353742563428275\n",
      "Average Recall Score: 0.42420634920634925\n",
      "Std Recall Score: 0.25663867631143666\n"
     ]
    }
   ],
   "source": [
    "bal = []\n",
    "recall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    #bal = []\n",
    "    #recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects']\n",
    "        nb = GaussianNB()\n",
    "        nb.fit(X,Y)\n",
    "        y_pred = nb.predict(fold[1][0])\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,y_pred)\n",
    "        r = recall_score(l,y_pred)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "    #bal = np.array(bal)\n",
    "    #recall = np.array(recall)\n",
    "    #print(\"Recall:\",np.mean(recall))\n",
    "    #print(\"Balanced Accuracy:\",np.mean(bal))\n",
    "    #print(\"====================\")\n",
    "    #mbal += [np.mean(bal)]\n",
    "    #mrecall += [np.mean(recall)]\n",
    "\n",
    "bal = np.array(bal)\n",
    "recall = np.array(recall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(bal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(bal))\n",
    "print(\"Average Recall Score:\",np.mean(recall))\n",
    "print(\"Std Recall Score:\",np.std(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.6281864487088368\n",
      "Std Balanced Accuracy: 0.13449505707542075\n",
      "Average Recall Score: 0.5359126984126985\n",
      "Std Recall Score: 0.2969674745910376\n"
     ]
    }
   ],
   "source": [
    "mbal = []\n",
    "mrecall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    bal = []\n",
    "    recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects'].values\n",
    "        tf.reset_default_graph()\n",
    "        os_elm1 = OS_ELM(\n",
    "        # the number of input nodes.\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        # the number of hidden nodes.\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        # the number of output nodes.\n",
    "        n_output_nodes= 2,\n",
    "        # loss function.\n",
    "        # the default value is 'mean_squared_error'.\n",
    "        # for the other functions, we support\n",
    "        # 'mean_absolute_error', 'categorical_crossentropy', and 'binary_crossentropy'.\n",
    "        loss='binary_crossentropy',\n",
    "        # activation function applied to the hidden nodes.\n",
    "        # the default value is 'sigmoid'.\n",
    "        # for the other functions, we support 'linear' and 'tanh'.\n",
    "        # NOTE: OS-ELM can apply an activation function only to the hidden nodes.\n",
    "        activation='sigmoid',\n",
    "    )\n",
    "        Y = Y.reshape(-1,1)\n",
    "        #print(sum(Y),Y.shape)\n",
    "        Y = np.hstack((Y==False,Y))\n",
    "        #print(Y)\n",
    "        border = int(2*n_hidden_nodes)\n",
    "        Xtrain_init = X[:border]\n",
    "        Xtrain_seq = X[border:]\n",
    "        ytrain_init = Y[:border]\n",
    "        ytrain_seq = Y[border:]\n",
    "        os_elm1.init_train(Xtrain_init, ytrain_init)\n",
    "        batch_size = 64\n",
    "        for i in range(0, len(Xtrain_seq), batch_size):\n",
    "            x_batch = Xtrain_seq[i:i+batch_size]\n",
    "            t_batch = ytrain_seq[i:i+batch_size]\n",
    "            os_elm1.seq_train(x_batch, t_batch)\n",
    "        n_classes = n_output_nodes\n",
    "        y_pred = os_elm1.predict(fold[1][0])\n",
    "        #print(y_pred)\n",
    "        y_pred = softmax(y_pred)\n",
    "        res = []\n",
    "        for ys in y_pred:\n",
    "            res.append(np.argmax(ys))\n",
    "        res = np.array(res)\n",
    "        #print(y_pred,res)\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,res)\n",
    "        r = recall_score(l,res)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "    bal = np.array(bal)\n",
    "    recall = np.array(recall)\n",
    "    #print(\"Recall:\",np.mean(recall))\n",
    "    #print(\"Balanced Accuracy:\",np.mean(bal))\n",
    "    #print(\"====================\")\n",
    "    mbal += [np.mean(bal)]\n",
    "    mrecall += [np.mean(recall)]\n",
    "\n",
    "mbal = np.array(mbal)\n",
    "mrecall = np.array(mrecall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(mbal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(mbal))\n",
    "print(\"Average Recall Score:\",np.mean(mrecall))\n",
    "print(\"Std Recall Score:\",np.std(mrecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.6338565401284892\n",
      "Std Balanced Accuracy: 0.07626298673688779\n",
      "Average Recall Score: 0.4533730158730159\n",
      "Std Recall Score: 0.20090155281983765\n"
     ]
    }
   ],
   "source": [
    "mbal = []\n",
    "mrecall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    bal = []\n",
    "    recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects'].values\n",
    "        tf.reset_default_graph()\n",
    "        os_elm1 = OS_ELM(\n",
    "        # the number of input nodes.\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        # the number of hidden nodes.\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        # the number of output nodes.\n",
    "        n_output_nodes=2,\n",
    "        # loss function.\n",
    "        # the default value is 'mean_squared_error'.\n",
    "        # for the other functions, we support\n",
    "        # 'mean_absolute_error', 'categorical_crossentropy', and 'binary_crossentropy'.\n",
    "        loss='binary_crossentropy',\n",
    "        # activation function applied to the hidden nodes.\n",
    "        # the default value is 'sigmoid'.\n",
    "        # for the other functions, we support 'linear' and 'tanh'.\n",
    "        # NOTE: OS-ELM can apply an activation function only to the hidden nodes.\n",
    "        activation='sigmoid',\n",
    "    )\n",
    "        Y = Y.reshape(-1,1)\n",
    "        Yo = np.hstack((Y==False,Y))\n",
    "        border = int(2*n_hidden_nodes)\n",
    "        Xtrain_init = X[:border]\n",
    "        Xtrain_seq = X[border:]\n",
    "        ytrain_init = Yo[:border]\n",
    "        ytrain_seq = Yo[border:]\n",
    "        os_elm1.init_train(Xtrain_init, ytrain_init)\n",
    "        batch_size = 64\n",
    "        for i in range(0, len(Xtrain_seq), batch_size):\n",
    "            x_batch = Xtrain_seq[i:i+batch_size]\n",
    "            t_batch = ytrain_seq[i:i+batch_size]\n",
    "            os_elm1.seq_train(x_batch, t_batch)\n",
    "        n_classes = n_output_nodes\n",
    "        y_predo = os_elm1.predict(fold[1][0])\n",
    "        y_predo = softmax(y_predo)\n",
    "        res = []\n",
    "        for ys in y_predo:\n",
    "            res.append(np.argmax(ys))\n",
    "        res = np.array(res)\n",
    "        \n",
    "        svm = SVC(gamma = \"auto\",kernel = \"rbf\")\n",
    "        svm.fit(X,Y.ravel())\n",
    "        y_preds = svm.predict(fold[1][0])\n",
    "        y_preds = y_preds.reshape(-1,1)\n",
    "        \n",
    "        lr = LogisticRegression(solver = \"lbfgs\")\n",
    "        lr.fit(X,Y.ravel())\n",
    "        y_predl = lr.predict(fold[1][0])\n",
    "        y_predl = y_predl.reshape(-1,1)\n",
    "        res = res.reshape(-1,1)\n",
    "        y_pred = ((y_predl + y_preds + res) >= 2)*1\n",
    "        y_pred = y_pred.ravel()\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,y_pred)\n",
    "        r = recall_score(l,y_pred)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "    bal = np.array(bal)\n",
    "    recall = np.array(recall)\n",
    "    #print(\"Recall:\",np.mean(recall))\n",
    "    #print(\"Balanced Accuracy:\",np.mean(bal))\n",
    "    #print(\"====================\")\n",
    "    mbal += [np.mean(bal)]\n",
    "    mrecall += [np.mean(recall)]\n",
    "\n",
    "mbal = np.array(mbal)\n",
    "mrecall = np.array(mrecall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(mbal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(mbal))\n",
    "print(\"Average Recall Score:\",np.mean(mrecall))\n",
    "print(\"Std Recall Score:\",np.std(mrecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.5840322198531154\n",
      "Std Balanced Accuracy: 0.07872853822513894\n",
      "Average Recall Score: 0.3192460317460318\n",
      "Std Recall Score: 0.16719598957272064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "mbal = []\n",
    "mrecall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    bal = []\n",
    "    recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects']\n",
    "        clf = BaggingClassifier(base_estimator=SVC(kernel = \"rbf\",gamma = \"auto\"),n_estimators=10,random_state = 0)\n",
    "        clf.fit(X,Y)\n",
    "        y_pred = clf.predict(fold[1][0])\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,y_pred)\n",
    "        r = recall_score(l,y_pred)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "    bal = np.array(bal)\n",
    "    recall = np.array(recall)\n",
    "    #print(\"Recall:\",np.mean(recall))\n",
    "    #print(\"Balanced Accuracy:\",np.mean(bal))\n",
    "    #print(\"====================\")\n",
    "    mbal += [np.mean(bal)]\n",
    "    mrecall += [np.mean(recall)]\n",
    "\n",
    "mbal = np.array(mbal)\n",
    "mrecall = np.array(mrecall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(mbal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(mbal))\n",
    "print(\"Average Recall Score:\",np.mean(mrecall))\n",
    "print(\"Std Recall Score:\",np.std(mrecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Average Balanced Accuracy: 0.6357648469835696\n",
      "Std Balanced Accuracy: 0.08242535751875663\n",
      "Average Recall Score: 0.5148809523809523\n",
      "Std Recall Score: 0.2292611294351741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "mbal = []\n",
    "mrecall = []\n",
    "for fold in folds:\n",
    "    result = fold[0]\n",
    "    bal = []\n",
    "    recall = []\n",
    "    for key in result.keys():\n",
    "        dat = result[key]\n",
    "        X = dat.iloc[:,:-1]\n",
    "        Y = dat['defects']\n",
    "        clf = BaggingClassifier(base_estimator=LogisticRegression(solver = \"lbfgs\"),n_estimators=10,random_state = 0)\n",
    "        clf.fit(X,Y)\n",
    "        y_pred = clf.predict(fold[1][0])\n",
    "        l = np.array([bool(i) for i in fold[1][1]])\n",
    "        b = balanced_accuracy_score(l,y_pred)\n",
    "        r = recall_score(l,y_pred)\n",
    "        bal += [b]\n",
    "        recall += [r]\n",
    "    bal = np.array(bal)\n",
    "    recall = np.array(recall)\n",
    "    #print(\"Recall:\",np.mean(recall))\n",
    "    #print(\"Balanced Accuracy:\",np.mean(bal))\n",
    "    #print(\"====================\")\n",
    "    mbal += [np.mean(bal)]\n",
    "    mrecall += [np.mean(recall)]\n",
    "\n",
    "mbal = np.array(mbal)\n",
    "mrecall = np.array(mrecall)\n",
    "print(\"=============\")\n",
    "print(\"Average Balanced Accuracy:\",np.mean(mbal))\n",
    "print(\"Std Balanced Accuracy:\",np.std(mbal))\n",
    "print(\"Average Recall Score:\",np.mean(mrecall))\n",
    "print(\"Std Recall Score:\",np.std(mrecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
